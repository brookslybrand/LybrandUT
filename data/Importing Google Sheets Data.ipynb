{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Transform the Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google spread sheet data\n",
    "\n",
    "files = ['Fall 2015.xlsx', 'Spring 2017.xlsx']#, 'Spring 2016.xlsx']\n",
    "google_sheets_transformed = pd.DataFrame(columns=['Class', 'Description', 'Start date', 'Start time', 'End date', 'End time', 'Duration'])\n",
    "\n",
    "for file in files:\n",
    "    sheets = pd.ExcelFile(file).sheet_names\n",
    "    \n",
    "    for sheet in sheets:\n",
    "        # load in the data\n",
    "        original = pd.read_excel(file, sheet_name=sheet)\n",
    "\n",
    "        # get the class names\n",
    "        classNames = original.keys()[1:]\n",
    "\n",
    "        # create a new dataframe\n",
    "        new = pd.DataFrame(columns=['Class', 'Description', 'Start date', 'Start time', 'End date', 'End time', 'Duration'])\n",
    "\n",
    "        # transform the data into the correct format\n",
    "        new['Class'] = np.ravel([[className]*len(original) for className in classNames])\n",
    "        new['Start date'] = pd.Series(np.concatenate([original['Date'].values]*len(classNames)))\n",
    "        new['End date'] = pd.Series(np.concatenate([original['Date'].values]*len(classNames)))\n",
    "        new['Duration'] = pd.to_timedelta(np.ravel([original[className].values for className in classNames]), unit='h')\n",
    "        # remove data with 0 for the Duration, and resort and index\n",
    "        new = new[new['Duration'] > pd.Timedelta(0)]\n",
    "\n",
    "        currentLen = len(google_sheets_transformed)\n",
    "        new.index = range(currentLen, currentLen + len(new))\n",
    "\n",
    "        # append to the main DataFrame\n",
    "        google_sheets_transformed = google_sheets_transformed.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle data\n",
    "toggle_data = pd.read_csv('Toggl_time_entries_2017-01-01_to_2019-01-01.csv')\n",
    "# conver the duration\n",
    "toggle_data['Duration'] = pd.to_timedelta(toggle_data['Duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Toggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two dataframes\n",
    "data = pd.concat([\n",
    "                  google_sheets_transformed,\n",
    "                  ]\n",
    "                ).sort_values(by=['Start date', 'Class'])\n",
    "\n",
    "# conver to seconds\n",
    "data['Duration'] = pd.to_numeric(data['Duration'])/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (pd.Timestamp)):\n",
    "            return obj.isoformat()\n",
    "            \n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumped = json.dumps(data.values, cls=NumpyEncoder)\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(json.loads(dumped), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lybrand_ut]",
   "language": "python",
   "name": "conda-env-lybrand_ut-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
